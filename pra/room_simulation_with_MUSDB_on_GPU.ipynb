{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Room simulation with MUSDB18\n",
    "\n",
    "In this notebook we will simulate a recording of *Perdrix* on a room on which we control certain parameters\n",
    "\n",
    "We will then perform a Source Separation Algorithm on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "import librosa\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import operator\n",
    "import soundfile as sf\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "from numpy import typing\n",
    "import pyroomacoustics as pra\n",
    "from mir_eval.separation import bss_eval_sources\n",
    "from src import performance, data_processing_copy, fast_nmf_copy\n",
    "import stempeg\n",
    "from pyroomacoustics.directivities import (\n",
    "    DirectivityPattern,\n",
    "    DirectionVector,\n",
    "    CardioidFamily,\n",
    ")\n",
    "\n",
    "path_in = \"./data/musdb18/train/\"\n",
    "path_musdb18 = \"./data/musdb18/train/\"\n",
    "save_path = \"./test/prise_de_son_perf/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "files_in, files_title = data_processing_copy.get_files(path_in)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Room\n",
    "room_dimension = [5, 9, 3]\n",
    "abs_coef = 0.35\n",
    "microphone_locations = np.c_[[1.5, 6, 1], [2, 7, 1], [3, 7, 1], [3.5, 6, 1], [2.5, 4.5, 1.5], [2.5, 4.5, 1.5], [2.5, 4.5, 1.5]]\n",
    "\n",
    "appoint = DirectivityPattern.CARDIOID\n",
    "couple = DirectivityPattern.CARDIOID\n",
    "\n",
    "dir_1 = CardioidFamily(\n",
    "    orientation = DirectionVector(azimuth=170, colatitude=90, degrees=True),\n",
    "    pattern_enum = appoint,\n",
    ")\n",
    "dir_2_3 = CardioidFamily(\n",
    "    orientation = DirectionVector(azimuth=90, colatitude=90, degrees=True),\n",
    "    pattern_enum = appoint,\n",
    ")\n",
    "dir_4 = CardioidFamily(\n",
    "    orientation = DirectionVector(azimuth=10, colatitude=90, degrees=True),\n",
    "    pattern_enum = appoint,\n",
    ")\n",
    "dir_5 = CardioidFamily(\n",
    "    orientation = DirectionVector(azimuth=60, colatitude=100, degrees=True),\n",
    "    pattern_enum = couple,\n",
    ")\n",
    "dir_6 = CardioidFamily(\n",
    "    orientation = DirectionVector(azimuth=90, colatitude=100, degrees=True),\n",
    "    pattern_enum = couple,\n",
    ")\n",
    "dir_7 = CardioidFamily(\n",
    "    orientation = DirectionVector(azimuth=120, colatitude=100, degrees=True),\n",
    "    pattern_enum = couple,\n",
    ")\n",
    "\n",
    "directivities = [dir_1, dir_2_3, dir_2_3, dir_4, dir_5, dir_6, dir_7]\n",
    "\n",
    "source_locations = [[1.2, 6.3, 1], [2, 7.5, 1], [3, 7.5, 1], [4.2, 6.3, 1]]\n",
    "source_dir = None\n",
    "\n",
    "# Audio processing\n",
    "\n",
    "song_path = files_in[35]\n",
    "start_time = 30\n",
    "audio_length = 10\n",
    "L=2048\n",
    "hop=512\n",
    "\n",
    "# Algorithm parameters\n",
    "\n",
    "n_basis = 32\n",
    "n_iter = 300"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shoebox_recording(\n",
    "    room_dimension, \n",
    "    abs_coef, \n",
    "    microphone_locations,\n",
    "    microphone_dir = None,\n",
    "    rate = 44100,\n",
    "    display_room = False,\n",
    "    ):\n",
    "\n",
    "    \"\"\" \n",
    "    \n",
    "    this function creates a shoebox room (defined \n",
    "    with its geometry, room absorption, source \n",
    "    locations and microphones locations)\n",
    "\n",
    "    Input\n",
    "    ---\n",
    "    - room_dimension:       Array [length, width, height]   = room dimensions\n",
    "    - abs_coef:             float                           = Sabine absorbtion coefficient\n",
    "    - microphone_locations: np.c_ [[3D locations],...]      = microphones locations\n",
    "    - microphone_dir:       optionnal, directivity          = microphones directivity\n",
    "    - rate:                 optionnal, int                  = rate of the microphone (44100 default)\n",
    "    - display_room:         optionnal, bool                 = room display (False default)\n",
    "\n",
    "    Output\n",
    "    ---\n",
    "\n",
    "    - room:                 ShoeBox                         = room\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Create an shoebox room\n",
    "    room = pra.ShoeBox(room_dimension, fs=rate, max_order=15, absorption=abs_coef, sigma2_awgn=1e-8)\n",
    "\n",
    "    # Add microphone array\n",
    "    mic_array = pra.MicrophoneArray(microphone_locations, rate)\n",
    "    room.add_microphone_array(mic_array, directivity=microphone_dir)\n",
    "    \n",
    "    if display_room:\n",
    "        fig, ax = room.plot()\n",
    "        lim = 9\n",
    "        ax.set_xlim([0, lim])\n",
    "        ax.set_ylim([0, lim])\n",
    "        ax.set_zlim([0, lim])\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "\n",
    "    return room\n",
    "\n",
    "def compute_si_sdr(reference, estimation):\n",
    "    \"\"\"\n",
    "    Fonction provenant du github https://github.com/fgnt/pb_bss et servant à estimer\n",
    "    le si-sdr entre un signal de reference et un signal estimé\n",
    "\n",
    "\n",
    "    Scale-Invariant Signal-to-Distortion Ratio (SI-SDR)\n",
    "    Args:\n",
    "        reference: numpy.ndarray, [..., T]\n",
    "        estimation: numpy.ndarray, [..., T]\n",
    "    Returns:\n",
    "        SI-SDR\n",
    "    [1] SDR– Half- Baked or Well Done?\n",
    "    http://www.merl.com/publications/docs/TR2019-013.pdf\n",
    "    >>> np.random.seed(0)\n",
    "    >>> reference = np.random.randn(100)\n",
    "    >>> si_sdr(reference, reference)\n",
    "    inf\n",
    "    >>> si_sdr(reference, reference * 2)\n",
    "    inf\n",
    "    >>> si_sdr(reference, np.flip(reference))\n",
    "    -25.127672346460717\n",
    "    >>> si_sdr(reference, reference + np.flip(reference))\n",
    "    0.481070445785553\n",
    "    >>> si_sdr(reference, reference + 0.5)\n",
    "    6.3704606032577304\n",
    "    >>> si_sdr(reference, reference * 2 + 1)\n",
    "    6.3704606032577304\n",
    "    >>> si_sdr([1., 0], [0., 0])  # never predict only zeros\n",
    "    nan\n",
    "    >>> si_sdr([reference, reference], [reference * 2 + 1, reference * 1 + 0.5])\n",
    "    array([6.3704606, 6.3704606])\n",
    "    \"\"\"\n",
    "    estimation, reference = np.broadcast_arrays(estimation, reference)\n",
    "\n",
    "    assert reference.dtype == np.float64, reference.dtype\n",
    "    assert estimation.dtype == np.float64, estimation.dtype\n",
    "\n",
    "    reference_energy = np.sum(reference**2, axis=-1, keepdims=True)\n",
    "\n",
    "    # This is $\\alpha$ after Equation (3) in [1].\n",
    "    optimal_scaling = (\n",
    "        np.sum(reference * estimation, axis=-1, keepdims=True) / reference_energy\n",
    "    )\n",
    "\n",
    "    # This is $e_{\\text{target}}$ in Equation (4) in [1].\n",
    "    projection = optimal_scaling * reference\n",
    "\n",
    "    # This is $e_{\\text{res}}$ in Equation (4) in [1].\n",
    "    noise = estimation - projection\n",
    "\n",
    "    ratio = np.sum(projection**2, axis=-1) / np.sum(noise**2, axis=-1)\n",
    "    return 10 * np.log10(ratio)\n",
    "\n",
    "def compute_perf(y, ref):\n",
    "\n",
    "    \"\"\"\n",
    "    Fonction permettant de calculer les performances de la méthode de séparation de sources\n",
    "    suivant les critères SDR, SI-SDR, SIR et SAR.\n",
    "\n",
    "    Inputs:\n",
    "    ------------------------------------------------------\n",
    "\n",
    "    y: numpy.ndarray (n_channels, n_sources, n_samples)\n",
    "        Matrice contenant les signaux audios estimés\n",
    "\n",
    "    ref: numpy.ndarray (n_channels, n_sources, n_samples)\n",
    "        Matrice contenant les signaux audios de référence\n",
    "\n",
    "\n",
    "    Outputs:\n",
    "    ------------------------------------------------------\n",
    "\n",
    "    sdr: list\n",
    "        Liste contenant les valeurs de SDR pour chaque source\n",
    "\n",
    "    si_sdr: list\n",
    "        Liste contenant les valeurs de SI-SDR pour chaque source\n",
    "\n",
    "    sir: list\n",
    "        Liste contenant les valeurs de SIR pour chaque source\n",
    "\n",
    "    sar: list\n",
    "        Liste contenant les valeurs de SAR pour chaque source\n",
    "\n",
    "    perm: list\n",
    "        Liste contenant les permutations des sources estimées par rapport aux sources de référence\n",
    "\n",
    "    \"\"\"\n",
    "    sdr = []\n",
    "    si_sdr = []\n",
    "    sir = []\n",
    "    sar = []\n",
    "    perm = []\n",
    "\n",
    "    # On parcourt les microphones\n",
    "    for i in range(y.shape[0]):\n",
    "\n",
    "        # On prend le minimum entre le nombre de samples du signal de référence et celui de l'estimation\n",
    "        m_ = np.minimum(y[i].shape[1], ref[i].shape[1])\n",
    "\n",
    "        # On calcule les performances\n",
    "        sdr_, sir_, sar_, perm_ = bss_eval_sources(ref[i, :, :m_], y[i, :, :m_])\n",
    "        si_sdr_ = compute_si_sdr(ref[i, :, :m_], y[i, :, :m_])\n",
    "\n",
    "        # On ajoute les performances pour tous les microphones\n",
    "        sdr.append(sdr_)\n",
    "        si_sdr.append(si_sdr_)\n",
    "        sir.append(sir_)\n",
    "        sar.append(sar_)\n",
    "        perm.append(perm_)\n",
    "\n",
    "    return sdr, si_sdr, sir, sar, perm\n",
    "\n",
    "def ecoute_separation_micro(mic, y, save):\n",
    "    \"\"\"Fonction permettant d'écouter les audios séparés pour un micro donné et de les sauvegarder si save=True\n",
    "\n",
    "    Args:\n",
    "        mic (int): index du microphone dont on veut écouter la séparation\n",
    "        y (array): array contenant les signaux audios séparés pour chaque microphones\n",
    "        save (boolean): True si on veut sauvegarder les audios séparés, False sinon\n",
    "    \"\"\"\n",
    "\n",
    "    for source_n in range(len(y[0])):\n",
    "        print(\n",
    "            \"Listening of Audio at microphone \"\n",
    "            + str(mic)\n",
    "            + \" for source \"\n",
    "            + str(source_n)\n",
    "        )\n",
    "        display(ipd.Audio(y[mic][source_n], rate=44100))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all(\n",
    "    room_dimension, \n",
    "    abs_coef, \n",
    "    microphone_locations, \n",
    "    directivities,\n",
    "    source_locations, \n",
    "    source_dir, \n",
    "    song_path,\n",
    "    start_time,\n",
    "    audio_length,\n",
    "    n_iter,\n",
    "    n_basis,\n",
    "    display_audio = False,\n",
    "    display_room = False\n",
    "    ):\n",
    "\n",
    "    \"\"\"Fonction permettant de calculer les performances d'une séparation audio\n",
    "\n",
    "    Args:\n",
    "        room_dimension          (list):             dimensions de la pièce\n",
    "        abs_coef                (list):             coefficients d'absorption de la pièce\n",
    "        microphone_locations    (list):             liste contenant les coordonnées des microphones\n",
    "        directivities           (list):             liste contenant les directivités des microphones\n",
    "        shoebox_room            (object):           objet contenant les informations de la pièce\n",
    "        source_locations        (list):             liste contenant les coordonnées des sources\n",
    "        source_dir              (list):             liste contenant les directions des sources\n",
    "        song_path               (string):           chemin vers le fichier audio\n",
    "        start_time              (int):              temps de début de l'enregistrement\n",
    "        audio_length            (int):              durée de l'enregistrement\n",
    "        n_iter                  (int):              nombre d'itérations\n",
    "        n_basis                 (int):              nombre de bases\n",
    "        L                       (int, optional):    taille de la fenêtre. Defaults to 2048.\n",
    "        hop                     (int, optional):    pas de la fenêtre. Defaults to 512.\n",
    "        display_audio           (bool, optional):   True si on veut afficher les audios. Defaults to False.\n",
    "        display_room            (bool, optional):   True si on veut afficher la pièce. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        likelihood              (list):             liste contenant les likelihoods\n",
    "        overall_sdr             (float):            SDR moyen\n",
    "        overall_sir             (float):            SIR moyen\n",
    "        overall_sar             (float):            SAR moyen\n",
    "        overall_si_sdr          (float):            SI-SDR moyen\n",
    "    \"\"\"\n",
    "\n",
    "    shoebox_room = shoebox_recording(room_dimension, abs_coef, microphone_locations, directivities)\n",
    "\n",
    "    X, separate_recordings, mics_signals = data_processing_copy.room_spectrogram_from_musdb(\n",
    "        shoebox_room, \n",
    "        source_locations, \n",
    "        source_dir, \n",
    "        song_path,\n",
    "        start_time,\n",
    "        audio_length\n",
    "        )\n",
    "\n",
    "    ### Running FastMNMF2_split algorithm ###\n",
    "\n",
    "    Y, W_NFK, E_NFL, U_NLK, H_NKT, Y_FTM, T_NKO, P_NOT, g_NM, Q_FMM, likelihood = fast_nmf_copy.fastmnmf2_split(\n",
    "    X.transpose(1, 2, 0),\n",
    "    E_NFL=None,\n",
    "    P_NOT=None,\n",
    "    n_src=4,\n",
    "    n_iter=n_iter,\n",
    "    n_components=n_basis,\n",
    "    n_notes=X.shape[2] - 1,\n",
    "    n_activations=X.shape[1] - 1,\n",
    "    mic_index=\"all\",\n",
    "    )\n",
    "\n",
    "    Y = Y.transpose(0, 3, 2, 1)\n",
    "\n",
    "    ### Reconstructing the signals ###\n",
    "\n",
    "    # STFT parameters\n",
    "    win_a = pra.hamming(L)\n",
    "    win_s = pra.transform.stft.compute_synthesis_window(win_a, hop)\n",
    "\n",
    "    y = []\n",
    "    for i in range(len(Y)):\n",
    "        signal_ = pra.transform.stft.synthesis(Y[i], L, hop, win=win_s)\n",
    "        signal_ = signal_[L - hop :, :].T\n",
    "        y.append(signal_)\n",
    "\n",
    "    \n",
    "    ### Compute performance metrics ###\n",
    "     \n",
    "    y = np.array(y)\n",
    "    ref = separate_recordings.transpose(1, 0, 2)\n",
    "\n",
    "    microphones, sources, time_step = ref.shape\n",
    "    non_zero = np.ones_like(ref[0, 0, :])*1e-10\n",
    "\n",
    "    for mic in range(microphones):\n",
    "        for src in range(sources):\n",
    "            ref[mic, src, :] = ref[mic, src, :] + non_zero\n",
    "\n",
    "    y = y.astype(np.float64)\n",
    "    sdr, si_sdr, sir, sar, perm = compute_perf(y, ref)\n",
    "    \n",
    "    ### Extract performance metrics ###\n",
    "\n",
    "    overall_sdr = []\n",
    "    overall_sir = []\n",
    "    overall_sar = []\n",
    "    overall_si_sdr = []\n",
    "\n",
    "    for micro in range(4):\n",
    "            overall_sdr.append(sdr[micro][micro])\n",
    "            overall_sir.append(sir[micro][micro])\n",
    "            overall_sar.append(sar[micro][micro])\n",
    "            overall_si_sdr.append(si_sdr[micro][micro])\n",
    "\n",
    "    return likelihood, overall_sdr, overall_sir, overall_sar, overall_si_sdr\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdr_list = []\n",
    "sir_list = []\n",
    "sar_list = []\n",
    "si_sdr_list = []\n",
    "\n",
    "for i in range (3):\n",
    "    likelihood, overall_sdr, overall_sir, overall_sar, overall_si_sdr = compute_all(\n",
    "        room_dimension, \n",
    "        abs_coef, \n",
    "        microphone_locations, \n",
    "        directivities,\n",
    "        source_locations, \n",
    "        source_dir, \n",
    "        files_in[i],\n",
    "        start_time,\n",
    "        audio_length,\n",
    "        n_iter,\n",
    "        n_basis\n",
    "        )\n",
    "    \n",
    "    sdr_list.append(overall_sdr)\n",
    "    sir_list.append(overall_sir)\n",
    "    sar_list.append(overall_sar)\n",
    "    si_sdr_list.append(overall_si_sdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [sdr_list, sir_list, sar_list, si_sdr_list]\n",
    "\n",
    "plt.boxplot(data, labels=['overall SDR', 'overall SIR', 'overall SAR', 'overall SI-SDR'])\n",
    "plt.title('Boxplot of objective evaluation metrics')\n",
    "# plt.savefig('./test/surdeterm/complete objective evaluation.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P3S",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bcf48ba9a50210d1e854c799ec234b583cb3d3c227338c482a5f5f02bbeeb4ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
