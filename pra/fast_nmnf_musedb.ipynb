{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QYQ3OATSdv_W"
   },
   "source": [
    "## Simulation d'une situation réel avec Pyroomacoustics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: \n",
    "\n",
    "Il y a plusieurs possibilités dans ce notebook: \n",
    "\n",
    "- Utilisation de différents algorithmes (Celui de Louis, ou celui de pyroomacoustics)\n",
    "Pour utiliser l'un ou l'autre, il faut faire attention aux variables globales (définies avec des MAJUSCULES). \n",
    "- Utilisation de fichiers MuseDB ou de fichiers WAV.\n",
    "- Possibilité de plot les performances en fonction de l'avancée de l'algorithme. (PLOT_PERFORMANCE) mais ATTENTION, cela est implémenté que pour l'algo pyroom pour l'instant. \n",
    "- Possibilité de sauvegarder les figures et les audios (SAVE_FIG et SAVE_AUDIO), cela va créé les dossiers correspondants sous 'test'\n",
    "\n",
    "- Puis bien sûr, possibilité de modifier toutes les données concernant l'emplacement des microphones, dimensions de la salle etc... au fur et à mesure du notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "import librosa\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import stempeg\n",
    "import itertools\n",
    "import operator\n",
    "import pyroomacoustics as pra\n",
    "import wave\n",
    "import random as rd\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from pyroomacoustics.directivities import (\n",
    "    DirectivityPattern,\n",
    "    DirectionVector,\n",
    "    CardioidFamily,\n",
    ")\n",
    "from numpy import typing\n",
    "from mir_eval.separation import bss_eval_sources\n",
    "\n",
    "path_in = \"./data/musedb/\"\n",
    "save_path = \"./test/surdeterm/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import performance, data_processing, fast_nmf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement d'un fichier MuseDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All files in MUSDB18 dataset is a multitrack format composed of 5 stereo streams, each one encoded in AAC @256kbps. These signals correspond to:\n",
    "\n",
    "- `0` - The mixture,\n",
    "- `1` - The drums,\n",
    "- `2` - The bass,\n",
    "- `3` - The rest of the accompaniment,\n",
    "- `4` - The vocals.\n",
    "\n",
    "```S.shape = (5, time_step , 2)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "files_in, files_tilte = data_processing.get_files(path_in, \".mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in files_in[:3]:\n",
    "    S, rate = stempeg.read_stems(path)\n",
    "    display(ipd.Audio(S[0][:, 0], rate=rate))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test avec un fichier wav classique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_files = [\n",
    "    [\"data/samples/BACH Cello Suite 1, Prelude, Violin - Kateryna Timokhina.wav\"],\n",
    "    [\"data/samples/Bach_ Prélude, Cello suite Nr.1  Ophélie Gaillard.wav\"],\n",
    "    [\"data/samples/Bach_ Prélude, Cello suite Nr.1  Ophélie Gaillard.wav\"],\n",
    "    [\"data/samples/BACH Cello Suite 1, Prelude, Violin - Kateryna Timokhina.wav\"],\n",
    "]\n",
    "\n",
    "signals = [\n",
    "    np.concatenate([librosa.load(f, sr=None, mono=False)[0] for f in source_files])\n",
    "    for source_files in wav_files\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition des variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_PERFORMANCE = False  # plot les performances en fonction des itérations de l'algorithme => Implémenté que pour pyroomacoustics\n",
    "MUSEDB = True  # Si True, on utilise la base de données MUSEDB, sinon on utilise les fichiers wav_files\n",
    "LOUIS = True  # Si True, on utilise l'algorithme de LOUIS, sinon on utilise l'algorithme de pyroomacoustics\n",
    "SAVE_FIG = (\n",
    "    False  # Si True, on sauvegarde toutes les figures dans les sous-dossiers de 'test'\n",
    ")\n",
    "SAVE_AUDIO = False  # Si True, on sauvegarde tous les fichiers audio dans le sous-dossiers 'audio' de 'test'\n",
    "SAVE_PERF = (\n",
    "    False  # Si True, on sauvegarde toutes les figures dans les sous-dossiers de 'test'\n",
    ")\n",
    "TYPE = \"stft\"\n",
    "\n",
    "# Paramètres des microphones\n",
    "mic_pattern = DirectivityPattern.CARDIOID\n",
    "MIC_DIR = CardioidFamily(\n",
    "    orientation=DirectionVector(azimuth=180, colatitude=60, degrees=True),\n",
    "    pattern_enum=mic_pattern,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permet de créé les dossiers de sauvegarde si les variables permettant la sauvegarde\n",
    "# sont à True\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"./test\")\n",
    "\n",
    "except OSError as error:\n",
    "    pass\n",
    "\n",
    "\n",
    "if SAVE_FIG:\n",
    "    try:\n",
    "        os.mkdir(save_path)\n",
    "\n",
    "        try:\n",
    "            os.mkdir(save_path + \"activation\")\n",
    "            os.mkdir(save_path + \"base\")\n",
    "            os.mkdir(save_path + \"spectro\")\n",
    "            os.mkdir(save_path + \"mix\")\n",
    "        except OSError as error:\n",
    "            pass\n",
    "\n",
    "    except OSError as error:\n",
    "        pass\n",
    "\n",
    "if SAVE_AUDIO:\n",
    "    try:\n",
    "        os.mkdir(save_path + \"audios\")\n",
    "        os.mkdir(save_path + \"audios/separation\")\n",
    "        os.mkdir(save_path + \"audios/no_separation\")\n",
    "\n",
    "        os.mkdir(save_path + \"audios/separation/micro_drums\")\n",
    "        os.mkdir(save_path + \"audios/separation/micro_bass\")\n",
    "        os.mkdir(save_path + \"audios/separation/micro_vocals\")\n",
    "        os.mkdir(save_path + \"audios/separation/micro_other\")\n",
    "        os.mkdir(save_path + \"audios/separation/micro_AB1\")\n",
    "        os.mkdir(save_path + \"audios/separation/micro_AB2\")\n",
    "\n",
    "        os.mkdir(save_path + \"audios/no_separation/micro_AB1\")\n",
    "        os.mkdir(save_path + \"audios/no_separation/micro_AB2\")\n",
    "        os.mkdir(save_path + \"audios/no_separation/micro_drums\")\n",
    "        os.mkdir(save_path + \"audios/no_separation/micro_bass\")\n",
    "        os.mkdir(save_path + \"audios/no_separation/micro_vocals\")\n",
    "        os.mkdir(save_path + \"audios/no_separation/micro_other\")\n",
    "\n",
    "    except OSError as error:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not MUSEDB:\n",
    "    print(\"working with custom signals\")\n",
    "\n",
    "    # Parametres de la room\n",
    "    room_dimension = [12, 20, 5]\n",
    "    abs_coef = 0.35\n",
    "\n",
    "    # Parametres des sources: noms et localisations dans la salle\n",
    "    source_names = [\"source1\", \"source2\", \"source3\", \"source4\"]\n",
    "    source_locations = [[2, 9, 1], [2, 11, 1], [3, 12, 1], [3, 7, 1]]\n",
    "\n",
    "    # Parametres des micros: noms et localisations dans la salle\n",
    "    microphone_names = [\"mic1\", \"mic2\", \"mic3\", \"mic4\", \"mic5\", \"mic6\"]\n",
    "    microphone_locations = np.c_[\n",
    "        [2.7, 9, 1], [2.7, 11, 1], [3.5, 12, 1], [3.5, 7, 1], [6, 9.6, 1], [6, 10.4, 1]\n",
    "    ]\n",
    "\n",
    "    # Parametres de la STFT\n",
    "    L = 2048\n",
    "    hop = L // 4\n",
    "\n",
    "    # Parametres de la musique\n",
    "    audio_length = 10\n",
    "    rate = 44100\n",
    "\n",
    "    # Création de la room\n",
    "    room = data_processing.shoebox_room(\n",
    "        room_dimension,\n",
    "        abs_coef,\n",
    "    )\n",
    "\n",
    "    # Ajout des sources et des microphones\n",
    "    room, separate_recordings, mics_signals = data_processing.room_sources_micro(\n",
    "        signals,\n",
    "        rate=rate,\n",
    "        audio_length=audio_length,\n",
    "        room=room,\n",
    "        source_locations=source_locations,\n",
    "        microphone_locations=microphone_locations,\n",
    "        microphone_names=microphone_names,\n",
    "        source_dir=None,\n",
    "        mic_dir=MIC_DIR,\n",
    "        display_room=True,\n",
    "    )\n",
    "\n",
    "    # Transformations des signaux audio en STFT_multichannel en prennant en compte la room et l'emplacement des micros et sources\n",
    "    X = data_processing.spectrogram_from_mics_signal(\n",
    "        mics_signals,\n",
    "        microphone_names,\n",
    "        rate=rate,\n",
    "        L=L,\n",
    "        hop=hop,\n",
    "        type=TYPE,\n",
    "        display_audio=True,\n",
    "        display_spectrogram=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MUSEDB:\n",
    "    print(\"working with MUSDB18\")\n",
    "\n",
    "    # Parametres de la room\n",
    "    room_dimension = [12, 20, 5]\n",
    "    abs_coef = 0.35\n",
    "\n",
    "    # Parametres des sources: noms et localisations dans la salle\n",
    "    # 1: Drums | 2: Bass | 3: Accompaniemenet | 4: Vocals\n",
    "    source_names = [\"drums\", \"bass\", \"other\", \"vocals\"]\n",
    "    source_locations = [[2, 9, 1], [2, 11, 1], [3, 12, 1], [3, 7, 1]]\n",
    "\n",
    "    # Parametres des micros: noms et localisations dans la salle\n",
    "    # 1: Drums | 2: Bass | 3: Accompaniemenet | 4: Vocals | 5 et 6 couples AB (espacés de 80cm)\n",
    "    microphone_names = [\"drums\", \"bass\", \"other\", \"vocals\", \"AB1\", \"AB2\"]\n",
    "    microphone_locations = np.c_[\n",
    "        [2.7, 9, 1], [2.7, 11, 1], [3.5, 12, 1], [3.5, 7, 1], [6, 9.6, 1], [6, 10.4, 1]\n",
    "    ]\n",
    "\n",
    "    # Prend une musique au hasard\n",
    "    ind = rd.randint(0, len(files_in))\n",
    "    song_path = files_in[2]\n",
    "\n",
    "    data, rate = stempeg.read_stems(song_path)\n",
    "    audio_list = data[1:, :].transpose(0, 2, 1)\n",
    "\n",
    "    # Parametres de la STFT\n",
    "    L = 4096\n",
    "    hop = L // 4\n",
    "\n",
    "    # Parametres de la musique\n",
    "    audio_length = 10\n",
    "\n",
    "    # Création de la room\n",
    "    room = data_processing.shoebox_room(\n",
    "        room_dimension,\n",
    "        abs_coef,\n",
    "    )\n",
    "\n",
    "    # Ajout des sources et des microphones\n",
    "    room, separate_recordings, mics_signals = data_processing.room_sources_micro(\n",
    "        audio_list,\n",
    "        rate=rate,\n",
    "        audio_length=audio_length,\n",
    "        room=room,\n",
    "        source_locations=source_locations,\n",
    "        microphone_locations=microphone_locations,\n",
    "        microphone_names=microphone_names,\n",
    "        source_dir=None,\n",
    "        mic_dir=MIC_DIR,\n",
    "        display_room=True,\n",
    "    )\n",
    "\n",
    "    # Transformations des signaux audio en STFT_multichannel en prennant en compte la room et l'emplacement des micros et sources\n",
    "    X = data_processing.spectrogram_from_mics_signal(\n",
    "        mics_signals,\n",
    "        microphone_names,\n",
    "        rate=rate,\n",
    "        L=L,\n",
    "        hop=hop,\n",
    "        type=TYPE,\n",
    "        display_audio=True,\n",
    "        display_spectrogram=False,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout de la Fast MNMF pour la séparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape_separate_recordings=(n_sources, n_mics, n_samples)\n",
    "# ref0 = separate_recordings[:, 0, :]\n",
    "SDR, SIR, SAR, PERM = [], [], [], []\n",
    "\n",
    "win_a = pra.hamming(L)\n",
    "win_s = pra.transform.stft.compute_synthesis_window(win_a, hop)\n",
    "\n",
    "# Callback function to monitor the convergence of the algorithm\n",
    "def convergence_callback_micro(Y):\n",
    "    global SDR, SIR, SAR, PERM\n",
    "    sdr = np.zeros(len(Y), dtype=object)\n",
    "    sir = np.zeros(len(Y), dtype=object)\n",
    "    sar = np.zeros(len(Y), dtype=object)\n",
    "    perm = np.zeros(len(Y), dtype=object)\n",
    "\n",
    "    for i in range(len(Y)):\n",
    "        signal_ = pra.transform.stft.synthesis(Y[i], L, hop, win=win_s)\n",
    "        signal_ = signal_[L - hop :, :].T\n",
    "\n",
    "        # shape_separate_recordings=(n_sources, n_mics, n_samples)\n",
    "        ref_ = separate_recordings[:, i, :]\n",
    "\n",
    "        m_ = np.minimum(signal_.shape[1], ref_.shape[1])\n",
    "\n",
    "        sdr[i], sir[i], sar[i], perm[i] = bss_eval_sources(\n",
    "            ref_[:, :m_], signal_[:, :m_]\n",
    "        )\n",
    "\n",
    "    SDR.append(sdr)\n",
    "    SIR.append(sir)\n",
    "    SAR.append(sar)\n",
    "    PERM.append(perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametres de l'algorithme\n",
    "n_basis = 16\n",
    "n_iter = 100\n",
    "\n",
    "if PLOT_PERFORMANCE:\n",
    "    print(\"Running fastmnmf2 with callback function\")\n",
    "    Y, W_NFK, H_NKT, Y_FTM, g_NM, Q_FMM = fast_nmf.fastmnmf2_pyroom(\n",
    "        X,\n",
    "        n_src=len(source_names),\n",
    "        n_iter=n_iter,\n",
    "        n_components=n_basis,\n",
    "        mic_index=\"all\",\n",
    "        W0=None,\n",
    "        accelerate=True,\n",
    "        callback=convergence_callback_micro,\n",
    "    )\n",
    "\n",
    "elif LOUIS:\n",
    "    print(\"Running fastmnmf2 with Louis custom algorithm\")\n",
    "    (\n",
    "        Y,\n",
    "        W_NFK,\n",
    "        H_NKT,\n",
    "        g_NM,\n",
    "        Q_FMM,\n",
    "        Qx_FTM,\n",
    "        X_tilde_FTM,\n",
    "        Y_tilde_FTM,\n",
    "    ) = fast_nmf.fast_MNMF2(\n",
    "        X.transpose(1, 0, 2),\n",
    "        n_iter=n_iter,\n",
    "        n_microphones=len(microphone_names),\n",
    "        n_sources=len(source_names),\n",
    "        n_time_frames=X.shape[0],\n",
    "        n_freq_bins=X.shape[1],\n",
    "        n_basis=n_basis,\n",
    "        algo=\"IP\",\n",
    "        mic_index=None,\n",
    "        split=True,\n",
    "        n_activations=X.shape[0] - 1,\n",
    "        n_notes=X.shape[1] - 1,\n",
    "    )\n",
    "    Y = Y.transpose(0, 3, 2, 1)\n",
    "\n",
    "elif not PLOT_PERFORMANCE and not LOUIS:\n",
    "    print(\"Running fastmnmf2 without callback function\")\n",
    "    Y, W_NFK, H_NKT, Y_FTM, g_NM, Q_FMM = fast_nmf.fastmnmf2_pyroom(\n",
    "        X,\n",
    "        n_src=len(source_names),\n",
    "        n_iter=n_iter,\n",
    "        n_components=n_basis,\n",
    "        mic_index=\"all\",\n",
    "        W0=None,\n",
    "        accelerate=True,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute performance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TYPE == \"stft\":\n",
    "    # STFT parameters\n",
    "    win_a = pra.hamming(L)\n",
    "    win_s = pra.transform.stft.compute_synthesis_window(win_a, hop)\n",
    "\n",
    "    y = []\n",
    "    for i in range(len(Y)):\n",
    "        signal_ = pra.transform.stft.synthesis(Y[i], L, hop, win=win_s)\n",
    "        signal_ = signal_[L - hop :, :].T\n",
    "        y.append(signal_)\n",
    "\n",
    "elif TYPE == \"cqt\":\n",
    "    y = []\n",
    "    for i in range(len(Y)):\n",
    "        signal_ = librosa.icqt(\n",
    "            Y[i].transpose(2, 1, 0),\n",
    "            sr=rate,\n",
    "            hop_length=hop,\n",
    "            fmin=None,\n",
    "            bins_per_octave=12,\n",
    "            tuning=0.0,\n",
    "            filter_scale=1,\n",
    "            norm=1,\n",
    "            sparsity=0.01,\n",
    "            window=\"hann\",\n",
    "            scale=True,\n",
    "            length=None,\n",
    "            res_type=\"fft\",\n",
    "            dtype=None,\n",
    "        )\n",
    "        y.append(signal_)\n",
    "\n",
    "# shape of y = (n_mics, n_sources, n_samples)\n",
    "y = np.array(y)\n",
    "# shape of ref = (n_mics, n_sources, n_samples)\n",
    "ref = separate_recordings.transpose(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdr, si_sdr, sir, sar, perm = performance.compute_perf(y, ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print des sdr et sir finaux\n",
    "print(\"SDR final : \", np.mean(sdr))\n",
    "print(\"SI_SDR final : \", np.mean(si_sdr))\n",
    "print(\"SIR final : \", np.mean(sir))\n",
    "print(\"SAR final : \", np.mean(sar))\n",
    "\n",
    "perf_mean = np.array(\n",
    "    [\n",
    "        {\"sdr_mean\": np.mean(sdr)},\n",
    "        {\"si_sdr_mean\": np.mean(si_sdr)},\n",
    "        {\"sir_mean\": np.mean(sir)},\n",
    "        {\"sar_mean\": np.mean(sar)},\n",
    "    ],\n",
    "    dtype=object,\n",
    ")\n",
    "perf_final = np.array(\n",
    "    [\n",
    "        {\"sdr_final\": sdr},\n",
    "        {\"si_sdr_final\": si_sdr},\n",
    "        {\"sir_final\": sir},\n",
    "        {\"sar_final\": sar},\n",
    "    ],\n",
    "    dtype=object,\n",
    ")\n",
    "\n",
    "perf = np.concatenate((perf_mean, perf_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_PERF:\n",
    "    # save sdr, sir, sar in a csv file\n",
    "    np.savetxt(\n",
    "        save_path\n",
    "        + \"perf_\"\n",
    "        + str(song_path.split(\"/\")[2][:-9])\n",
    "        + \"_audio_length_\"\n",
    "        + str(audio_length)\n",
    "        + \"_n_basis_\"\n",
    "        + str(n_basis)\n",
    "        + \"_n_fft_\"\n",
    "        + str(L)\n",
    "        + \".csv\",\n",
    "        perf,\n",
    "        delimiter=\",\",\n",
    "        fmt=\"%s\",\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un peu de visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correspond à la séparation de source, micro_plot_sep\n",
    "mic_plot_sep = 5\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(10, 6)\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.specgram(ref[mic_plot_sep][0, :], NFFT=1024, Fs=room.fs)\n",
    "plt.title(\"Source 0 (target)\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.specgram(ref[mic_plot_sep][1, :], NFFT=1024, Fs=room.fs)\n",
    "plt.title(\"Source 1 (target)\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.specgram(y[mic_plot_sep][0, :], NFFT=1024, Fs=room.fs)\n",
    "plt.title(\"Source 0 (séparé)\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.specgram(y[mic_plot_sep][1, :], NFFT=1024, Fs=room.fs)\n",
    "plt.title(\"Source 1 (séparé)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.tight_layout(pad=2.5)\n",
    "fig.suptitle(\n",
    "    \"spectro_source01_micro_\"\n",
    "    + microphone_names[mic_plot_sep]\n",
    "    + str(song_path.split(\"/\")[2][:-9])\n",
    "    + \"_n_basis_\"\n",
    "    + str(n_basis)\n",
    "    + \"_n_fft_\"\n",
    "    + str(L)\n",
    ")\n",
    "\n",
    "if SAVE_FIG:\n",
    "    fig.savefig(\n",
    "        save_path\n",
    "        + \"spectro/\"\n",
    "        + \"spectro_source01_micro_\"\n",
    "        + microphone_names[mic_plot_sep]\n",
    "        + str(song_path.split(\"/\")[2][:-9])\n",
    "        + \"_audio_length_\"\n",
    "        + str(audio_length)\n",
    "        + \"_n_basis_\"\n",
    "        + str(n_basis)\n",
    "        + \"_n_fft_\"\n",
    "        + str(L)\n",
    "        + \".pdf\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correspond à la séparation de source, micro_plot_sep\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(10, 6)\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.specgram(ref[mic_plot_sep][2, :], NFFT=1024, Fs=room.fs)\n",
    "plt.title(\"Source 2 (clean)\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.specgram(ref[mic_plot_sep][3, :], NFFT=1024, Fs=room.fs)\n",
    "plt.title(\"Source 3 (clean)\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.specgram(y[mic_plot_sep][2, :], NFFT=1024, Fs=room.fs)\n",
    "plt.title(\"Source 2 (separated)\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.specgram(y[mic_plot_sep][3, :], NFFT=1024, Fs=room.fs)\n",
    "plt.title(\"Source 3 (separated)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.tight_layout(pad=2.5)\n",
    "fig.suptitle(\n",
    "    \"spectro_source23_micro_\"\n",
    "    + microphone_names[mic_plot_sep]\n",
    "    + str(song_path.split(\"/\")[2][:-9])\n",
    "    + \"_n_basis_\"\n",
    "    + str(n_basis)\n",
    "    + \"_n_fft_\"\n",
    "    + str(L)\n",
    ")\n",
    "\n",
    "if SAVE_FIG:\n",
    "    fig.savefig(\n",
    "        save_path\n",
    "        + \"spectro/\"\n",
    "        + \"spectro_source23_micro_\"\n",
    "        + microphone_names[mic_plot_sep]\n",
    "        + str(song_path.split(\"/\")[2][:-9])\n",
    "        + \"_audio_length_\"\n",
    "        + str(audio_length)\n",
    "        + \"_n_basis_\"\n",
    "        + str(n_basis)\n",
    "        + \"_n_fft_\"\n",
    "        + str(L)\n",
    "        + \".pdf\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correspond à la séparation de source, micro_plot_sep\n",
    "\n",
    "if PLOT_PERFORMANCE:\n",
    "\n",
    "    print(\"Plotting performance for fastmnmf2\")\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(10, 6)\n",
    "    a = np.array(SDR)\n",
    "    a = np.stack(a[:, mic_plot_perf])\n",
    "\n",
    "    b = np.array(SIR)\n",
    "    b = np.stack(b[:, mic_plot_perf])\n",
    "\n",
    "    plt.plot(np.arange(a.shape[0]) * 10, a[:, 0], label=\"SDR Source 0\", c=\"r\", ls=\"-\")\n",
    "    plt.plot(np.arange(a.shape[0]) * 10, a[:, 1], label=\"SDR Source 1\", c=\"r\", ls=\"--\")\n",
    "    plt.plot(np.arange(a.shape[0]) * 10, a[:, 2], label=\"SDR Source 2\", c=\"r\", ls=\":\")\n",
    "    plt.plot(np.arange(a.shape[0]) * 10, a[:, 3], label=\"SDR Source 3\", c=\"r\", ls=\"-.\")\n",
    "\n",
    "    plt.plot(np.arange(b.shape[0]) * 10, b[:, 0], label=\"SIR Source 0\", c=\"b\", ls=\"-\")\n",
    "    plt.plot(np.arange(b.shape[0]) * 10, b[:, 1], label=\"SIR Source 1\", c=\"b\", ls=\"--\")\n",
    "    plt.plot(np.arange(b.shape[0]) * 10, b[:, 2], label=\"SIR Source 2\", c=\"b\", ls=\":\")\n",
    "    plt.plot(np.arange(b.shape[0]) * 10, b[:, 3], label=\"SIR Source 3\", c=\"b\", ls=\"-.\")\n",
    "\n",
    "    plt.legend(ncol=1)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"dB\")\n",
    "    plt.grid()\n",
    "    plt.title(\"performance microphone 0\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ecoute maintenant "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pas de séparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Listening of Audio at each microphones without separation\")\n",
    "\n",
    "SAVE_AUDIO = True\n",
    "\n",
    "for micro_n in range(len(mics_signals)):\n",
    "    print(\"microphone \", microphone_names[micro_n])\n",
    "    display(ipd.Audio(mics_signals[micro_n], rate=44100))\n",
    "    if SAVE_AUDIO:\n",
    "        wavfile.write(\n",
    "            save_path\n",
    "            + \"audios/no_separation/micro_\"\n",
    "            + microphone_names[micro_n]\n",
    "            + \"/test_\"\n",
    "            + str(song_path.split(\"/\")[2][:-9])\n",
    "            + \"_globals_micro_\"\n",
    "            + microphone_names[micro_n]\n",
    "            + \".wav\",\n",
    "            44100,\n",
    "            mics_signals[micro_n].astype(np.float32),\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Séparation des sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecoute_separation_micro(mic, y, save):\n",
    "    \"\"\"Fonction permettant d'écouter les audios séparés pour un micro donné et de les sauvegarder si save=True\n",
    "\n",
    "    Args:\n",
    "        mic (int): index du microphone dont on veut écouter la séparation\n",
    "        y (array): array contenant les signaux audios séparés pour chaque microphones\n",
    "        save (boolean): True si on veut sauvegarder les audios séparés, False sinon\n",
    "    \"\"\"\n",
    "\n",
    "    for source_n in range(len(y[0])):\n",
    "        if source_n == 0:\n",
    "            print(\"Drums séparé microphone \", microphone_names[mic])\n",
    "            display(ipd.Audio(y[mic][source_n], rate=44100))\n",
    "            if save:\n",
    "                wavfile.write(\n",
    "                    save_path\n",
    "                    + \"audios/separation/micro_\"\n",
    "                    + microphone_names[mic]\n",
    "                    + \"/\"\n",
    "                    + str(song_path.split(\"/\")[2][:-9])\n",
    "                    + \"_drums_micro_\"\n",
    "                    + microphone_names[mic]\n",
    "                    + \"_audio_length_\"\n",
    "                    + str(audio_length)\n",
    "                    + \"_n_basis_\"\n",
    "                    + str(n_basis)\n",
    "                    + \"_n_fft_\"\n",
    "                    + str(L)\n",
    "                    + \".wav\",\n",
    "                    44100,\n",
    "                    y[mic][source_n].astype(np.float32),\n",
    "                )\n",
    "\n",
    "        elif source_n == 1:\n",
    "            print(\"Bass séparé microphone \", microphone_names[mic])\n",
    "            display(ipd.Audio(y[mic][source_n], rate=44100))\n",
    "            if save:\n",
    "                wavfile.write(\n",
    "                    save_path\n",
    "                    + \"audios/separation/micro_\"\n",
    "                    + microphone_names[mic]\n",
    "                    + \"/\"\n",
    "                    + str(song_path.split(\"/\")[2][:-9])\n",
    "                    + \"_bass_micro_\"\n",
    "                    + microphone_names[mic]\n",
    "                    + \"_audio_length_\"\n",
    "                    + str(audio_length)\n",
    "                    + \"_n_basis_\"\n",
    "                    + str(n_basis)\n",
    "                    + \"_n_fft_\"\n",
    "                    + str(L)\n",
    "                    + \".wav\",\n",
    "                    44100,\n",
    "                    y[mic][source_n].astype(np.float32),\n",
    "                )\n",
    "\n",
    "        elif source_n == 2:\n",
    "            print(\"Accompaniement séparé microphone \", microphone_names[mic])\n",
    "            display(ipd.Audio(y[mic][source_n], rate=44100))\n",
    "            if save:\n",
    "                wavfile.write(\n",
    "                    save_path\n",
    "                    + \"audios/separation/micro_\"\n",
    "                    + microphone_names[mic]\n",
    "                    + \"/\"\n",
    "                    + str(song_path.split(\"/\")[2][:-9])\n",
    "                    + \"_other_micro_\"\n",
    "                    + microphone_names[mic]\n",
    "                    + \"_audio_length_\"\n",
    "                    + str(audio_length)\n",
    "                    + \"_n_basis_\"\n",
    "                    + str(n_basis)\n",
    "                    + \"_n_fft_\"\n",
    "                    + str(L)\n",
    "                    + \".wav\",\n",
    "                    44100,\n",
    "                    y[mic][source_n].astype(np.float32),\n",
    "                )\n",
    "\n",
    "        elif source_n == 3:\n",
    "            print(\"Vocals séparé microphone \", microphone_names[mic])\n",
    "            display(ipd.Audio(y[mic][source_n], rate=44100))\n",
    "            if save:\n",
    "                wavfile.write(\n",
    "                    save_path\n",
    "                    + \"audios/separation/micro_\"\n",
    "                    + microphone_names[mic]\n",
    "                    + \"/\"\n",
    "                    + str(song_path.split(\"/\")[2][:-9])\n",
    "                    + \"_vocals_micro_\"\n",
    "                    + microphone_names[mic]\n",
    "                    + \"_audio_length_\"\n",
    "                    + str(audio_length)\n",
    "                    + \"_n_basis_\"\n",
    "                    + str(n_basis)\n",
    "                    + \"_n_fft_\"\n",
    "                    + str(L)\n",
    "                    + \".wav\",\n",
    "                    44100,\n",
    "                    y[mic][source_n].astype(np.float32),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Listening of Audios at microphones 0 (couple) with separation\")\n",
    "ecoute_separation_micro(0, y, SAVE_AUDIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Listening of Audios at microphones 1 (couple) with separation\")\n",
    "ecoute_separation_micro(1, y, SAVE_AUDIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Listening of Audios at microphones 2 (couple) with separation\")\n",
    "ecoute_separation_micro(2, y, SAVE_AUDIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Listening of Audios at microphones 3 (couple) with separation\")\n",
    "ecoute_separation_micro(3, y, SAVE_AUDIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Listening of Audios at microphones 4 (couple) with separation\")\n",
    "ecoute_separation_micro(4, y, SAVE_AUDIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Listening of Audios at microphones 5 (couple) with separation\")\n",
    "ecoute_separation_micro(5, y, SAVE_AUDIO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des matrices intermédiaires"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Représentation of g, and G (covariance et matrice spatiale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOUIS:\n",
    "    plt.imshow(g_NM[:, :], cmap=\"inferno\", aspect=\"auto\")\n",
    "    plt.title(\"g_NM\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if SAVE_FIG:\n",
    "        plt.savefig(\n",
    "            save_path\n",
    "            + \"mix/\"\n",
    "            + \"g_mn_\"\n",
    "            + str(song_path.split(\"/\")[2])\n",
    "            + \"_n_basis_\"\n",
    "            + str(n_basis)\n",
    "            + \"_n_fft_\"\n",
    "            + str(L)\n",
    "            + \".pdf\"\n",
    "        )\n",
    "\n",
    "\n",
    "elif LOUIS:\n",
    "    plt.imshow(g_NM[:, :], cmap=\"inferno\", aspect=\"auto\")\n",
    "    plt.title(\n",
    "        \"g_mn_\"\n",
    "        + str(song_path.split(\"/\")[2][:-9])\n",
    "        + \"_n_basis_\"\n",
    "        + str(n_basis)\n",
    "        + \"_n_fft_\"\n",
    "        + str(L)\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if SAVE_FIG:\n",
    "        plt.savefig(\n",
    "            save_path\n",
    "            + \"mix/\"\n",
    "            + \"g_mn_\"\n",
    "            + str(song_path.split(\"/\")[2][:-9])\n",
    "            + \"_audio_length_\"\n",
    "            + str(audio_length)\n",
    "            + \"_n_basis_\"\n",
    "            + str(n_basis)\n",
    "            + \"_n_fft_\"\n",
    "            + str(L)\n",
    "            + \".pdf\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G_mix(Q_FMM, g_NM):\n",
    "    g_NMM = []\n",
    "    for n_source in range(g_NM.shape[0]):\n",
    "        g_NMM.append(np.diag(g_NM[n_source]))\n",
    "\n",
    "    g_NMM = np.array(g_NMM)\n",
    "\n",
    "    G_NF = np.einsum(\n",
    "        \"fij, nij, ijf -> ni\",\n",
    "        np.linalg.inv(Q_FMM),\n",
    "        g_NMM,\n",
    "        np.linalg.inv(Q_FMM).conj().T,\n",
    "    )\n",
    "    return G_NF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_NF\n",
    "G_NF = G_mix(Q_FMM, g_NM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log(np.abs(G_NF)), cmap=\"inferno\", aspect=\"auto\")\n",
    "plt.colorbar()\n",
    "plt.title(\n",
    "    \"G_NF_\"\n",
    "    + str(song_path.split(\"/\")[2][:-9])\n",
    "    + \"_n_basis_\"\n",
    "    + str(n_basis)\n",
    "    + \"_n_fft_\"\n",
    "    + str(L)\n",
    ")\n",
    "plt.tight_layout()\n",
    "\n",
    "if SAVE_FIG:\n",
    "    plt.savefig(\n",
    "        save_path\n",
    "        + \"mix/\"\n",
    "        + \"G_NF_\"\n",
    "        + str(song_path.split(\"/\")[2][:-9])\n",
    "        + \"_audio_length_\"\n",
    "        + str(audio_length)\n",
    "        + \"_n_basis_\"\n",
    "        + str(n_basis)\n",
    "        + \"_n_fft_\"\n",
    "        + str(L)\n",
    "        + \".pdf\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Représentation de W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(10, 6)\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(np.log(W_NFK[0, :, :]), cmap=\"inferno\", aspect=\"auto\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Matrice de base W0\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(np.log(W_NFK[1, :, :]), cmap=\"inferno\", aspect=\"auto\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Matrice de base W1\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(np.log(W_NFK[2, :, :]), cmap=\"inferno\", aspect=\"auto\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Matrice de base W2\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(np.log(W_NFK[3, :, :]), cmap=\"inferno\", aspect=\"auto\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Matrice de base W3\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.tight_layout(pad=2.5)\n",
    "fig.suptitle(\n",
    "    \"W_NFK_\"\n",
    "    + str(song_path.split(\"/\")[2][:-9])\n",
    "    + \"_n_basis_\"\n",
    "    + str(n_basis)\n",
    "    + \"_n_fft_\"\n",
    "    + str(L)\n",
    ")\n",
    "\n",
    "if SAVE_FIG:\n",
    "    fig.savefig(\n",
    "        save_path\n",
    "        + \"base/\"\n",
    "        + \"W_NFK_\"\n",
    "        + str(song_path.split(\"/\")[2][:-9])\n",
    "        + \"_audio_length_\"\n",
    "        + str(audio_length)\n",
    "        + \"_n_basis_\"\n",
    "        + str(n_basis)\n",
    "        + \"_n_fft_\"\n",
    "        + str(L)\n",
    "        + \".pdf\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Représentation des activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(10, 6)\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(H_NKT[0, :, :], cmap=\"inferno\", aspect=\"auto\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Matrice de base H0\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(H_NKT[1, :, :], cmap=\"inferno\", aspect=\"auto\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Matrice de base H1\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(H_NKT[2, :, :], cmap=\"inferno\", aspect=\"auto\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Matrice de base H2\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(H_NKT[3, :, :], cmap=\"inferno\", aspect=\"auto\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Matrice de base H3\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.tight_layout(pad=2.5)\n",
    "fig.suptitle(\n",
    "    \"H_NKT_\"\n",
    "    + str(song_path.split(\"/\")[2][:-9])\n",
    "    + \"_n_basis_\"\n",
    "    + str(n_basis)\n",
    "    + \"_n_fft_\"\n",
    "    + str(L)\n",
    ")\n",
    "\n",
    "if SAVE_FIG:\n",
    "    fig.savefig(\n",
    "        save_path\n",
    "        + \"activation/\"\n",
    "        + \"H_NKT_\"\n",
    "        + str(song_path.split(\"/\")[2][:-9])\n",
    "        + \"_audio_length_\"\n",
    "        + str(audio_length)\n",
    "        + \"_n_basis_\"\n",
    "        + str(n_basis)\n",
    "        + \"_n_fft_\"\n",
    "        + str(L)\n",
    "        + \".pdf\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P3S",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2011a595c94b6a73b54060f6a4d9915a152f934cd74fcad2403d0e39c89de16a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
